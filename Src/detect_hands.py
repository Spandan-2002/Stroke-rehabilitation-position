# -*- coding: utf-8 -*-
"""Detect_hands.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18NUzc2qvvQG6oMIV33fMj-LBBspKaxuS
"""

import cv2
import mediapipe as mp
import numpy as np
from collections import deque

# Initialize MediaPipe Hands
mp_hands = mp.solutions.hands
hand_detector = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.7)

# Use a deque to track previous bounding boxes for smoothing
hand_history = deque(maxlen=5)

def detect_hands_in_frame(image):
    """ Detect hands and return bounding boxes. """
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    results = hand_detector.process(image_rgb)

    hand_boxes = []
    if results.multi_hand_landmarks:
        height, width, _ = image.shape
        for hand_landmarks in results.multi_hand_landmarks:
            x_coords = [lm.x * width for lm in hand_landmarks.landmark]
            y_coords = [lm.y * height for lm in hand_landmarks.landmark]
            x_min, x_max = int(min(x_coords)), int(max(x_coords))
            y_min, y_max = int(min(y_coords)), int(max(y_coords))
            hand_boxes.append((x_min, y_min, x_max, y_max))

    # Store only valid detections
    if hand_boxes:
        hand_history.append(hand_boxes)

    # Apply smoothing only if history is not empty
    if hand_history:
        smoothed_boxes = []
        for i in range(len(hand_boxes)):
            # Gather corresponding boxes from history
            past_boxes = [frame[i] for frame in hand_history if len(frame) > i]
            if past_boxes:
                smoothed_box = np.mean(past_boxes, axis=0).astype(int).tolist()
                smoothed_boxes.append(smoothed_box)
        return smoothed_boxes
    else:
        return []